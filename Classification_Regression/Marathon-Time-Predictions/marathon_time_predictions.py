# -*- coding: utf-8 -*-
"""marathon-time-predictions.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/shravan-18/Machine-Learning-Projects/blob/main/Classification_Regression/Marathon-Time-Predictions/marathon-time-predictions.ipynb

# **Marathon time Predictions**

## **Import libraries**
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

!pip install pandas-profiling

"""## **Data Exploration**"""

from pandas_profiling import ProfileReport

df = pd.read_csv('/kaggle/input/marathon-time-predictions/MarathonData.csv')
profile = ProfileReport(df, title="Profiling Report")

profile.to_notebook_iframe()

"""## **Data Preprocessing**"""

# Check head of dataframe
df.head()

# Check unique values of each column
for i in df.columns:
    if type(i[0])!='int64' and type(i[0])!='float64':
        print(i, df[i].unique())

# Check shape of dataframe and check null value count
print(df.shape)
print(df.isnull().sum())

# Check types of each field
print(df.dtypes)

df_copy = df.copy() # Make a copy of the dataset
df = df.drop("CrossTraining", axis=1) # Drop column with mostly NULL Values

df.describe()

len(df["Marathon"].unique()), len(df["CATEGORY"].unique()), len(df["Category"].unique()), len(df["Name"].unique())

# Drop Marathon as it has only 1 value, and names because it has high cardinality
df = df.drop(["Marathon", "Name"], axis=1)

# Handle Category Column's NULL values
filtered_df = df[df['Category'].notna()]
df = filtered_df
df.isna().sum()

# One-Hot Encode the CATEGORY Column
OH_CATEGORY = pd.get_dummies(df["CATEGORY"], drop_first=True).astype(int)
OH_CATEGORY.head()

# Concat the One hot encoded dataframe and the original dataframe
df = pd.concat([df, OH_CATEGORY], axis=1)
df = df.drop("CATEGORY", axis=1) # Drop the one hot encoded column

print(df.dtypes)

# Check the rows with this weird value
df[df['Wall21'] == ' -   ']

# Calculate mean of the available rows in the column "Wall21"
b=0
c=0
for i in df["Wall21"].unique():
    if i == ' -   ':
        continue
    elif float(i):
        c += float(i)
        b += 1
b, c

# Replace the weird string values with the mean of that column
Mean = c/b
df.loc[df['Wall21'] == ' -   ', 'Wall21'] = Mean
df.head()

df["Wall21"] = df["Wall21"].astype(np.float64)
print(df.dtypes)

# Label encode the Category Column
# Import label encoder
from sklearn import preprocessing

# label_encoder object knows
# how to understand word labels.
label_encoder = preprocessing.LabelEncoder()

# Encode labels in column 'species'.
df['Category']= label_encoder.fit_transform(df['Category'])

df = df.drop_duplicates() # Drop duplicate rows, if any
df.shape

"""## **Split data into train and test splits**"""

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler

X = df.drop(['id', 'MarathonTime'], axis=1)
y = df['MarathonTime']

scaler = StandardScaler() # To scale the data

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

!pip install pycaret

from pycaret.regression import *

data = df.drop('id', axis=1) # Create temp dataframe to use for pycaret
s = setup(data, target = 'MarathonTime', session_id = 123)

# model training and selection
best = compare_models()

# evaluate trained model
evaluate_model(best)

from sklearn.ensemble import ExtraTreesRegressor
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import math

extra_trees_model = ExtraTreesRegressor(n_estimators=100, max_depth=None, random_state=42)
extra_trees_model.fit(X_train, y_train)

y_pred = extra_trees_model.predict(X_test)

print(f'Classifier: Extra Trees Regressor')
print(f'MSE: {mean_absolute_error(y_test, y_pred):.2f}')
print(f'MAE: {mean_squared_error(y_test, y_pred):.2f}')
print(f'RMSE: {math.sqrt(mean_squared_error(y_test, y_pred)):.2f}')
print(f'R2 Score: {r2_score(y_test, y_pred):.2f}')

"""## **Using manual model declarations as a dictionary of regressors**"""

# Import libraries for Machine Learning models and metrics

from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from sklearn.neighbors import KNeighborsRegressor
from xgboost import XGBRegressor
from catboost import CatBoostRegressor
from sklearn.ensemble import AdaBoostRegressor
from sklearn.ensemble import ExtraTreesRegressor
from lightgbm import LGBMRegressor

# Define a list of classifiers to test
regressors = {
    'Extra Trees Regressor': ExtraTreesRegressor(n_estimators=100),
    'Decision Tree': DecisionTreeRegressor(),
    'Random Forest': RandomForestRegressor(),
    'Support Vector Machine': SVR(),
    'K-Nearest Neighbors': KNeighborsRegressor(),
    'Light GBM': LGBMRegressor(),
    'XG Boost': XGBRegressor(),
    'CatBoost': CatBoostRegressor(),
    'AdaBoost': AdaBoostRegressor()
}

trained_models = {}

# Train and evaluate each classifier
for name, clf in regressors.items():
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)

    report = classification_report(y_test, y_pred)

    print(f'Classifier: {name}')
    print(f'Accuracy: {accuracy_score(y_test, y_pred):.2f}')
    print(f'Precision: {precision_score(y_test, y_pred, average="macro"):.2f}')
    print(f'Recall: {recall_score(y_test, y_pred, average="macro"):.2f}')
    print(f'F1 Score: {f1_score(y_test, y_pred, average="macro"):.2f}')
    print(f'Classification Report:\n{report}\n')

    trained_models[name] = clf

"""# **Conclusion - Final Metrics**

### Classifier: Extra Trees Regressor
### Mean Squared Error: 0.05
### Mean Absolute Error: 0.01
### Root Mean Square Error: 0.08
### R2 Score: 0.96
"""